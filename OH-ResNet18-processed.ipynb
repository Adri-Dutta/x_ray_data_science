{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"OH-ResNet18-processed.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"hc9D_Lhh6_yA","colab_type":"code","colab":{}},"source":["import torchvision\n","from torchvision import transforms, datasets, models\n","import torch\n","from torch import optim, cuda\n","from torch.utils.data import DataLoader, sampler\n","import torch.nn as nn\n","from PIL import Image\n","import os\n","import matplotlib.pyplot as plt\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5DK3e84eRErx","colab_type":"code","outputId":"1a3ebfd3-af41-431a-9975-bc2bfa04ace0","executionInfo":{"status":"ok","timestamp":1589049232765,"user_tz":300,"elapsed":20396,"user":{"displayName":"Shafin R Amin","photoUrl":"","userId":"03011341903103568622"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eLFQBBfFzGAH","colab_type":"text"},"source":["/*IMAGE PROCESSING */"]},{"cell_type":"code","metadata":{"id":"oIB8M6z8SM5H","colab_type":"code","colab":{}},"source":["labels = np.load('/content/drive/Shared drives/Data/Reprocessed data /augmentedLabels.npy',allow_pickle=True)\n","training = np.load('/content/drive/Shared drives/Data/Reprocessed data /augmentedTrainingData.npy',allow_pickle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3kFsJnZ2s3EH","colab_type":"code","colab":{}},"source":["#flips the numpy because tensorflow has channels at the end and pytorch has channels at the beginning\n","training = np.swapaxes(training,1,3)\n","training = np.swapaxes(training,2,3)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ySJpVXiyxUOT","colab_type":"text"},"source":["// Turns numpy arrays in to tensors"]},{"cell_type":"code","metadata":{"id":"sVnzT5GwVFqw","colab_type":"code","colab":{}},"source":["training = torch.from_numpy(training)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tG2HpNAjymbI","colab_type":"code","colab":{}},"source":["# just dummy data\n","training = torch.randn((100, 3, 224, 224))\n","labels = torch.zeros((100))\n","labels[50:] = 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mHjfNvmuxnfk","colab_type":"text"},"source":["//Turns labels form one HOT encoding to binary"]},{"cell_type":"code","metadata":{"id":"MKGH7gXBkvjS","colab_type":"code","colab":{}},"source":["# I don't believe that pytorch supports one hot encoding for the y_training data so changing it (I could be wrong)\n","labels_temp = np.zeros(labels.shape[0])\n","\n","for i in range(0,labels_temp.shape[0]): \n","  if labels[i][0] == 1:\n","    labels_temp[i] = 1\n","  else:\n","    labels_temp[i] = 0\n","\n","labels = torch.from_numpy(labels_temp)\n","\n","labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zmKOFdIPzrzs","colab_type":"code","colab":{}},"source":["labels = labels.type(torch.LongTensor)\n","labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4F7DJzLB9UkR","colab_type":"code","colab":{}},"source":["#Check to see if we have GPU availables\n","print(cuda.is_available())\n","print(cuda.device_count())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3W_OjvWvTTVX","colab_type":"code","colab":{}},"source":["device = torch.device('cuda:0')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C1uoEKdVyz2m","colab_type":"text"},"source":["/* END OF PROCESSING IMAGES, TIME FOR TRAINING */"]},{"cell_type":"markdown","metadata":{"id":"2KmZg3-Iza5-","colab_type":"text"},"source":["## Self Attention Module"]},{"cell_type":"code","metadata":{"id":"NCH26BgBzZpy","colab_type":"code","colab":{}},"source":["# https://github.com/heykeetae/Self-Attention-GAN/blob/master/sagan_models.py\n","class Self_Attn(nn.Module):\n","    \"\"\" Self attention Layer\"\"\"\n","    def __init__(self,in_dim):\n","        super(Self_Attn,self).__init__()\n","        self.chanel_in = in_dim\n","        \n","        self.query_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n","        self.key_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n","        self.value_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim , kernel_size= 1)\n","        self.gamma = nn.Parameter(torch.zeros(1))\n","\n","        self.softmax  = nn.Softmax(dim=-1) #\n","    def forward(self,x):\n","        \"\"\"\n","            inputs :\n","                x : input feature maps( B X C X W X H)\n","            returns :\n","                out : self attention value + input feature \n","                attention: B X N X N (N is Width*Height)\n","        \"\"\"\n","        m_batchsize,C,width ,height = x.size()\n","        proj_query  = self.query_conv(x).view(m_batchsize,-1,width*height).permute(0,2,1) # B X CX(N)\n","        proj_key =  self.key_conv(x).view(m_batchsize,-1,width*height) # B X C x (*W*H)\n","        energy =  torch.bmm(proj_query,proj_key) # transpose check\n","        attention = self.softmax(energy) # BX (N) X (N) \n","        proj_value = self.value_conv(x).view(m_batchsize,-1,width*height) # B X C X N\n","\n","        out = torch.bmm(proj_value,attention.permute(0,2,1) )\n","        out = out.view(m_batchsize,C,width,height)\n","        \n","        out = self.gamma*out + x\n","        return out,attention"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gr5w7jnSzZBo","colab_type":"code","colab":{}},"source":["class SAResNet(nn.Module):\n","\n","  def __init__(self, \n","               model, # original ResNet, \n","               module,\n","               device): # which layer to insert self attention\n","    super(SAResNet,self).__init__()\n","    self.model = model\n","    self.module = module\n","    self.device = device\n","    self.layers = [\n","        \"conv1\",\n","        \"bn1\",\n","        \"relu\",\n","        \"maxpool\",\n","        \"layer1\",\n","        \"layer2\",\n","        \"layer3\",\n","        \"layer4\",\n","        \"avgpool\"\n","    ]\n","    assert module in self.layers\n","    self.attention = None\n","    \n","  def forward(self, x):\n","    for layer in self.layers:\n","      x = self.model._modules[layer](x) # equivalent to self.model.layer(x)\n","      # We know to apply self attention here\n","      if layer == self.module:\n","        if self.attention is None:\n","          self.attention = Self_Attn(x.shape[1])\n","          self.attention.to(device)\n","        x, attention_map = self.attention(x)\n","    x = torch.flatten(x, 1)\n","    x = self.model.fc(x)\n","    return x, attention_map\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SSmVZ0SFSw0Y","colab_type":"code","colab":{}},"source":["resnet18 = models.resnet18(pretrained=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vzd6uBg2RhIv","colab_type":"code","colab":{}},"source":["n_classes = 2\n","resnet18.fc = torch.nn.Linear(in_features = resnet18.fc.in_features, out_features=n_classes)\n","resnet18.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nCkM3H9N3Y2d","colab_type":"text"},"source":["### Sanity Check Resnet Reimplementation"]},{"cell_type":"code","metadata":{"id":"9B2RgSNI3MZm","colab_type":"code","outputId":"3ee20fe9-b114-4027-c066-6d6c68577b33","executionInfo":{"status":"ok","timestamp":1588901195881,"user_tz":300,"elapsed":322,"user":{"displayName":"Kurtis David","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUIc74FWsGobd1WnCHb6AfmFTuHpxuFkLtbVo7ug=s64","userId":"09103434772709921876"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["resnet18(training[:2].to(device))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.0420,  0.1581],\n","        [ 0.4885,  0.3557]], device='cuda:0', grad_fn=<AddmmBackward>)"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"P8kDbUbN3XF2","colab_type":"code","colab":{}},"source":["sa_model = SAResNet(resnet18, \"layer1\", device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3M6GAH273lSN","colab_type":"code","colab":{}},"source":["x, attn_map = sa_model(training[:2].to(device))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cj4gmeGW8V82","colab_type":"code","outputId":"ade9fa41-fe1b-496a-b0ea-70ceb072088d","executionInfo":{"status":"ok","timestamp":1588902081728,"user_tz":300,"elapsed":489,"user":{"displayName":"Kurtis David","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUIc74FWsGobd1WnCHb6AfmFTuHpxuFkLtbVo7ug=s64","userId":"09103434772709921876"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["attn_map.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 3136, 3136])"]},"metadata":{"tags":[]},"execution_count":63}]},{"cell_type":"code","metadata":{"id":"l7sNXZN93qpN","colab_type":"code","outputId":"70b13a25-198d-424f-dfe4-08e63882db50","executionInfo":{"status":"ok","timestamp":1588901165884,"user_tz":300,"elapsed":161,"user":{"displayName":"Kurtis David","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUIc74FWsGobd1WnCHb6AfmFTuHpxuFkLtbVo7ug=s64","userId":"09103434772709921876"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["resnet18._modules['conv1']"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"4WZgL8NIFHJa","colab_type":"code","colab":{}},"source":["## Data Augmentations"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5chxM2NrFiri","colab_type":"code","colab":{}},"source":["class CustomTensorDataset(torch.utils.data.Dataset):\n","    \"\"\"TensorDataset with support of transforms.\n","    \"\"\"\n","    def __init__(self, tensors, labels, transform=None):\n","        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n","        self.tensors = tensors\n","        self.labels  = labels\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        x = self.tensors[index]\n","\n","        if self.transform:\n","            x = self.transform(x)\n","\n","        y = self.labels[index]\n","\n","        return x, y\n","\n","    def __len__(self):\n","        return self.tensors.size(0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QuFvYQXSGhZi","colab_type":"code","colab":{}},"source":["# what you want to actually modify, between the ToPILImage and ToTensor lines\n","train_augmentation = torchvision.transforms.Compose(\n","    [\n","        torchvision.transforms.ToPILImage(),\n","        torchvision.transforms.RandomHorizontalFlip(),\n","        torchvision.transforms.ToTensor()\n","    ]\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ml030R275VDK","colab_type":"code","colab":{}},"source":["## To use augmentations:\n","trainset = CustomTensorDataset(\n","  tensors = training, \n","  labels  = labels, \n","  transform = train_augmentation\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zrQEPeXsIJe1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n24dQ2xSrotZ","colab_type":"code","outputId":"2d8a9962-8c54-4f60-c1c4-fdbca552da97","executionInfo":{"status":"ok","timestamp":1588816629830,"user_tz":300,"elapsed":541,"user":{"displayName":"Erick Machado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbrvelxCZlMuq92e5lPNrlEfNsWHugNF79SDfbzg=s64","userId":"03224498450019070621"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["training[0].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 224, 224])"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"ybc_Qqdd5Zoj","colab_type":"code","colab":{}},"source":["trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2RfeMO9wVBNp","colab_type":"code","colab":{}},"source":["n_epochs = 5\n","optimizer = torch.optim.SGD(resnet18.parameters(), lr=0.1, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L0TfzRelUAcV","colab_type":"code","colab":{}},"source":["for epoch in range(n_epochs):\n","  for X_batch, Y_batch in trainloader:\n","    X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","    # Step 1: Zero out gradient\n","    optimizer.zero_grad()\n","    # Step 2: Compute Loss\n","    logits = resnet18(X_batch)\n","    loss = torch.nn.CrossEntropyLoss()(logits, Y_batch)\n","    #print(\"Loss:\", loss.item())\n","    # Step 3: Backpropagation\n","    loss.backward()\n","    # Step 4: Update Weights\n","    optimizer.step()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ohWacvtM2i6H","colab_type":"code","colab":{}},"source":["torch.save(resnet18.state_dict(), '/content/drive/My Drive/resnet18-crossentropy-processed.pth')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6cU8n7kRzNVS","colab_type":"code","colab":{}},"source":["test_labels = np.load('/content/drive/Shared drives/Data/Reprocessed data /Copy of TestAugLabels.npy',allow_pickle=True)\n","test_data = np.load('/content/drive/Shared drives/Data/Reprocessed data /Copy of TestDataAugData.npy',allow_pickle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0J-1lUnjwync","colab_type":"code","colab":{}},"source":["test_data = np.swapaxes(test_data,1,3)\n","test_data = np.swapaxes(test_data,2,3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qjGxNJ7hxNVq","colab_type":"code","colab":{}},"source":["test_data = torch.from_numpy(test_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vU8TCV5ox6_d","colab_type":"code","colab":{}},"source":["labels_temp = np.zeros(test_labels.shape[0])\n","\n","for i in range(0,labels_temp.shape[0]): \n","  if test_labels[i][0] == 1:\n","    labels_temp[i] = 1\n","  else:\n","    labels_temp[i] = 0\n","\n","test_labels = torch.from_numpy(labels_temp)\n","\n","test_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a5zFz7bDynVi","colab_type":"code","colab":{}},"source":["test_labels = test_labels.type(torch.LongTensor)\n","test_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FOEYLTHT4Mce","colab":{}},"source":["# make test datasetloader\n","testset = torch.utils.data.TensorDataset(test_data,test_labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gCKTjEQB4WvK","colab_type":"code","colab":{}},"source":["testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bTISwgj830He","colab_type":"code","colab":{}},"source":["def test_accuracy(model, test_loader):\n","\n","    # Do validation on the test set\n","    model.eval()\n","    model.to('cuda')\n","\n","    with torch.no_grad():\n","    \n","        accuracy = 0\n","    \n","        for images, labels in iter(test_loader):\n","    \n","            images, labels = images.to('cuda'), labels.to('cuda')\n","    \n","            output = model.forward(images)\n","\n","            probabilities = torch.exp(output)\n","        \n","            equality = (labels.data == probabilities.max(dim=1)[1])\n","        \n","            accuracy += equality.type(torch.FloatTensor).mean()\n","        \n","        print(\"Test Accuracy: {}\".format(accuracy/len(test_loader)))    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QMMaaVSu36WB","colab_type":"code","outputId":"d323dd47-72e8-4203-c2e9-a322119966a8","executionInfo":{"status":"ok","timestamp":1588817159013,"user_tz":300,"elapsed":2399,"user":{"displayName":"Erick Machado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbrvelxCZlMuq92e5lPNrlEfNsWHugNF79SDfbzg=s64","userId":"03224498450019070621"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["test_accuracy(resnet18,testloader)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test Accuracy: 0.8621794581413269\n"],"name":"stdout"}]}]}